{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0629f30-a83c-4e96-b258-d6f8a49de37f",
   "metadata": {},
   "source": [
    "# 第八章 机器学习心理学应用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6099f0-7bac-4540-9856-c59246a07772",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "本代码为《Python心理学应用》一书第八章机器学习的全部代码\n",
    "建议结合书本内容进行实操练习，以增进理解\n",
    "王利刚，wanglg@psych.ac.cn\n",
    "魏楚光，weicg@psych.ac.cn \n",
    "8-Dec-2024\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f3060f-1b5a-4c47-a315-b1e6864a4f3a",
   "metadata": {},
   "source": [
    "### 代码8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cd3e9a-9c63-40d2-8a63-f6aa4da41753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#(1)定义计算MSE的函数\n",
    "def calculate_MSE(x,y,w):\n",
    "    y_pre=w[0]*x+w[1]\n",
    "    MSE=np.mean((y_pre-y)**2)\n",
    "    return MSE\n",
    "#(2)计算均方误差对w0和w1的偏导数\n",
    "def gradient_MSE(x,y,w):\n",
    "    y_pre=w[0]*x+w[1]\n",
    "    d_w0=2*np.mean((y_pre-y)*x)\n",
    "    d_w1=2*np.mean(y_pre-y)\n",
    "    return d_w0,d_w1\n",
    "#(3)参数更新函数\n",
    "def updata_Parameter(x,y,tau_max):\n",
    "    alpha = 0.000001 # 学习率\n",
    "    tau_max = tau_max # 重复的最大次数\n",
    "    eps = 0.1 # 停止重复的梯度绝对值的阈值\n",
    "    w_history = np.zeros([tau_max, 2]) #用于存储参数变化的空白数组\n",
    "    MSE_history=[] #存储更新参数过程中对应的MSE值\n",
    "    w_history[0,:] = [2, 278]# 设置初始参数\n",
    "    for tau in range( 1, tau_max):\n",
    "        MSE = calculate_MSE(x, y, w_history[tau - 1])\n",
    "        MSE_history.append(MSE)\n",
    "        dMSE = gradient_MSE(x, y, w_history[tau - 1])\n",
    "        w_history[ tau, 0] = w_history[tau - 1, 0] - alpha * dMSE[ 0]  #跟新参数w0\n",
    "        w_history[ tau, 1] = w_history[ tau - 1, 1] - alpha * dMSE[ 1] #跟新参数w1\n",
    "        if max( np. absolute( dMSE)) < eps: # 结束判断\n",
    "           break\n",
    "    w0 = w_history[ tau_max-1, 0]\n",
    "    w1 = w_history[ tau_max-1, 1]\n",
    "    w_history = w_history.reshape((2,tau_max))\n",
    "    return w0, w1, dMSE, w_history,MSE_history\n",
    "#(4)运用梯度法降低法求参数，并绘图\n",
    "#生成心理健康水平和心理需求满足度得分数据\n",
    "np.random.seed(123)\n",
    "X=89+170*np.random.rand(21)#模拟生成心理需求满足度量表得分\n",
    "Y=300-180*np.exp(-0.02*X)+10*np.random.rand(21) #模拟生成心理健康量表得分\n",
    " #调用梯度法更新参数\n",
    "W0,W1,dMSE,w_history,MSE_history=updata_Parameter(X,Y,tau_max=100)\n",
    "print(\"迭代100次获得的系数分别是：w0={0},w2={1},MSE={2}\".format(W0,W1,MSE_history[-1]))\n",
    "#绘图部分\n",
    "fig,ax=plt.subplots(1,2)\n",
    "x=np.linspace(100,260,1000)#生成一个等差数列\n",
    "Y_pre=W0*x+W1 #使用等差数量形成对于的Y值，用于绘制直线\n",
    "#绘制散点图和拟合直线\n",
    "ax[0]. plot( X, Y, marker = 'o', linestyle = 'None', markeredgecolor = 'black', color = 'gray')\n",
    "# sns.regplot(x= X,y=Y ,color=\"gray\", line_kws={'color': 'gray', 'alpha': 0.7})\n",
    "ax[0].plot(x,Y_pre)\n",
    "ax[0].set_xlabel(\"需求满足度\",fontproperties='SimHei')\n",
    "ax[0].set_ylabel(\"心理健康\",fontproperties='SimHei')\n",
    "ax[0].set_title(\"梯度法参数的拟合情况\",fontproperties='SimHei')\n",
    "#绘制在迭代过程中MSE的变化情况\n",
    "ax[1].plot(MSE_history)\n",
    "ax[1].set_xlabel(\"迭代次数\",fontproperties='SimHei')\n",
    "ax[1].set_ylabel(\"MSE\")\n",
    "ax[1].set_title(\"梯度调参数的均方误差变化\",fontproperties='SimHei')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6300b2f6-976e-4106-833c-682342c93f92",
   "metadata": {},
   "source": [
    "### 代码8.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35394e70-daf9-4651-8d4c-3b1e520b67b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def entropy(p): #计算信息熵的函数     \n",
    "    if p == 0 or p == 1:\n",
    "        return 0\n",
    "    else:   \n",
    "        return -p * np.log2(p) - (1 - p) * np.log2(1 - p)\n",
    "#计算不同概率下，事件的信息熵\n",
    "probabilities = np.arange(0, 1.01, 0.01)#生成概率值从0到1，间隔0.01\n",
    "entropies = [entropy(p) for p in probabilities]#生成概率值对应的信息熵\n",
    "#绘制信息熵与事件概率的函数\n",
    "plt.plot(probabilities, entropies)\n",
    "plt.xlabel('事件发生的概率',fontproperties='SimHei')\n",
    "plt.ylabel('事件信息熵',fontproperties='SimHei')\n",
    "plt.title('事件发生概率与事件信息熵的关系',fontproperties='SimHei')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52c2864-1ad4-401f-b504-c7340563dfed",
   "metadata": {},
   "source": [
    "### 代码8.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7772e2-8ff6-4576-b5ff-10fac7b79874",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#(1)构建ID3的核心函数\n",
    "#定义计算信息熵的函数\n",
    "def entropy(labels):\n",
    "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "    probabilities = counts / len(labels)\n",
    "    entropy_value = -np.sum(probabilities * np.log2(probabilities))\n",
    "    return entropy_value\n",
    "#定义计算条件信息熵的函数\n",
    "def conditional_entropy(data, condition_col, target_col):\n",
    "    unique_conditions = data[condition_col].unique()\n",
    "    total_entropy = 0\n",
    "    for condition in unique_conditions:\n",
    "        subset = data[data[condition_col] == condition]\n",
    "        subset_prob = len(subset) / len(data)\n",
    "        subset_entropy = entropy(subset[target_col])\n",
    "        total_entropy += subset_prob * subset_entropy\n",
    "    return total_entropy\n",
    "#定义计算信息增益的函数\n",
    "def information_gain(data, feature_col, target_col):\n",
    "    original_entropy = entropy(data[target_col])\n",
    "    cond_entropy = conditional_entropy(data, feature_col, target_col)\n",
    "    return original_entropy - cond_entropy\n",
    "#选择最佳分裂特征的函数\n",
    "def choose_best_feature(data, target_col):\n",
    "    features = data.columns.drop(target_col)\n",
    "    best_feature = None\n",
    "    max_info_gain = -1\n",
    "    for feature in features:\n",
    "        ig = information_gain(data, feature, target_col)\n",
    "        if ig > max_info_gain:\n",
    "            max_info_gain = ig\n",
    "            best_feature = feature\n",
    "    return best_feature\n",
    "#多数表决函数，用于确定叶节点的类别\n",
    "def majority_vote(labels):\n",
    "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "    return unique_labels[np.argmax(counts)]\n",
    "#递归构建决策树\n",
    "def build_decision_tree(data, target_col, max_depth=None, min_samples_split=2, current_depth=0):\n",
    "    # 终止条件 1: 所有样本属于同一类别\n",
    "    if len(np.unique(data[target_col])) == 1:\n",
    "        return np.unique(data[target_col])[0]\n",
    "    # 终止条件 2: 没有可用于分裂的特征\n",
    "    if len(data.columns) == 1:\n",
    "        return majority_vote(data[target_col])\n",
    "    # 终止条件 3: 达到预设的最大深度\n",
    "    if max_depth is not None and current_depth >= max_depth:\n",
    "        return majority_vote(data[target_col])\n",
    "    # 终止条件 4: 节点中的样本数量少于预设的最小值\n",
    "    if len(data) < min_samples_split:\n",
    "        return majority_vote(data[target_col])\n",
    "    #选择最佳分裂特征\n",
    "    best_feature = choose_best_feature(data, target_col)\n",
    "    tree = {best_feature: {}}\n",
    "    # 根据最佳分裂特征的不同取值划分数据集\n",
    "    unique_values = data[best_feature].unique()\n",
    "    for value in unique_values:\n",
    "        subset = data[data[best_feature] == value].drop(columns=[best_feature])\n",
    "        # 递归构建子树，增加当前深度\n",
    "        subtree = build_decision_tree(subset, target_col, max_depth, min_samples_split, current_depth + 1)\n",
    "        tree[best_feature][value] = subtree\n",
    "    return tree\n",
    "#利用决策树进行预测\n",
    "def predict(tree, sample):\n",
    "    if not isinstance(tree, dict):\n",
    "        return tree\n",
    "    feature = list(tree.keys())[0]\n",
    "    value = sample[feature]\n",
    "    subtree = tree[feature].get(value)\n",
    "    if subtree is None:\n",
    "        # 如果测试样本的特征值在训练数据中未出现，可根据实际情况处理，这里简单返回多数类别\n",
    "        all_labels = []\n",
    "        for sub in tree[feature].values():\n",
    "            if not isinstance(sub, dict):\n",
    "                all_labels.append(sub)\n",
    "        return majority_vote(all_labels)\n",
    "    return predict(subtree, sample)\n",
    "#（2）准备数据包含标签和特征数值\n",
    "label_data=[0]*88+[1]*18 #是否心理疾患，总数是106人\n",
    "feature1=[1]*68+[0]*20+[1]*6+[0]*12  #是否有上家企业的推荐信\n",
    "feature2=[0]*84+[1]*4+[0]*12+ [1]*6 #是否存在持续一年没有固定工作\n",
    "data = pd.DataFrame({ \"是否心理疾患\": label_data, \"是否有推荐信\":feature1, \"是否1年无工作\":feature2})\n",
    "print(\"标签与特征数据库： \",data)\n",
    "#构建决策树，设置最大深度为 3，最小样本分割数为 2\n",
    "decision_tree = build_decision_tree(data, \"是否心理疾患\", max_depth=3, min_samples_split=2)\n",
    "print(\"决策树结构:\")\n",
    "print(decision_tree)\n",
    "#待预测样本\n",
    "sample = { \"是否有推荐信\": 0, \"是否1年无工作\": 1}\n",
    "#进行预测\n",
    "prediction = predict(decision_tree, sample)\n",
    "print(f\"预测结果: {'是' if prediction == 1 else '否'} 患有心理疾患\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97f6097-b494-4bd5-8037-982fcad945a9",
   "metadata": {},
   "source": [
    "### 代码8.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0e3c84-d9fa-4bf2-99ce-074c5ad54802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "#（1）模拟数据\n",
    "label_data = [0] * 88 + [1] * 18 # 是否心理疾患，总数是106人\n",
    "feature1 = [1] * 68 + [0] * 20 + [1] * 6 + [0] * 12 # 是否有上家企业的推荐信\n",
    "feature2 = [0] * 84 + [1] * 4 + [0] * 12 + [1] * 6 # 是否存在持续一年没有固定工作\n",
    "data = pd.DataFrame({\"是否心理疾患\": label_data,\"是否有推荐信\": feature1,\"是否1年无工作\": feature2})\n",
    "X = data.drop(\"是否心理疾患\", axis=1) #这是分裂特征数据\n",
    "y = data[\"是否心理疾患\"]  #这是标签数据\n",
    "#（2）划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#（3）创建决策树分类器\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)#训练模型\n",
    "#（4）使用训练好的模型进行预测并评估模型\n",
    "y_pred = clf.predict(X_test)#用输入测试数据，生成测试结果\n",
    "accuracy = accuracy_score(y_test, y_pred)#评估模型分类准确性\n",
    "print(f\"模型的准确率: {accuracy:.2f}\")\n",
    "#（5）以图形方式展示决策树\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei'] # 可根据系统情况选择其他中文字体，如 'Microsoft YaHei'\n",
    "plt.rcParams['axes.unicode_minus'] = False # 解决负号显示问题\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_tree(clf, feature_names=X.columns, class_names=['无心理疾患', '有心理疾患'], filled=True)\n",
    "plt.show()\n",
    "#（6）以文本形式输出决策树结构\n",
    "tree_text = export_text(clf, feature_names=list(X.columns))\n",
    "print(\"决策树文本结构： \",tree_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0dd494-fdaf-4a0c-aeae-207b8447440f",
   "metadata": {},
   "source": [
    "### 代码8.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08733899-fb03-43ce-af42-135730b075e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "#（1）模拟生成数据\n",
    "np.random.seed(42)\n",
    "n_samples =500\n",
    "# 生成人格各维度得分\n",
    "extroversion = np.random.rand(n_samples) * 10 # 外向性\n",
    "agreeableness = np.random.rand(n_samples) * 10 # 宜人性\n",
    "conscientiousness = np.random.rand(n_samples) * 10 # 责任心\n",
    "emotional_stability = np.random.rand(n_samples) * 10 # 情绪稳定性\n",
    "openness = np.random.rand(n_samples) * 10 # 开放性\n",
    "# 合并人格各维度得分作为特征矩阵\n",
    "X = np.column_stack((extroversion, agreeableness, conscientiousness, emotional_stability, openness))\n",
    "#模拟生成心理健康得分（目标变量）\n",
    "y = 0.5 * extroversion + 0.3 * agreeableness + 0.4 * conscientiousness + 0.6 * emotional_stability + 0.2 * openness + np.random.normal(0, 1, n_samples)#假设心理健康得分与人格维度得分存在一定的线性关系，并加入一些噪声\n",
    "#（2）训练阶段\n",
    "#① 数据准备\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  #划分训练集和测试集\n",
    "# ② 确定参数\n",
    "param_grid = {'n_estimators': [50, 100, 150],'max_features': ['sqrt', 'log2']}\n",
    "# 创建随机森林回归器实例\n",
    "rf = RandomForestRegressor(random_state=42, oob_score=True)\n",
    "# 创建网格搜索实例，使用 5 折交叉验证\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=5)\n",
    "# 在训练集上进行网格搜索\n",
    "grid_search.fit(X_train, y_train)\n",
    "# 获取最优参数\n",
    "best_params = grid_search.best_params_\n",
    "n_estimators = best_params['n_estimators']\n",
    "max_features_str = best_params['max_features']\n",
    "if max_features_str =='sqrt':\n",
    "    max_features =int(np.sqrt(X_train.shape[1]))\n",
    "elif max_features_str == 'log2':\n",
    "    max_features =int(np.log2(X_train.shape[1]))#\n",
    "#③ 自助采样及并构建决策树，后续步骤在 RandomForestRegressor 中自动完成\n",
    "rf = RandomForestRegressor(n_estimators=n_estimators, max_features=max_features, random_state=42, oob_score=True)#\n",
    "rf.fit(X_train, y_train)\n",
    "#（3）预测阶段\n",
    "# ① 输入待预测样本，集成预测结果在 predict 方法中自动完成\n",
    "y_pred = rf.predict(X_test)\n",
    "# ②模型评估\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "oob_score = rf.oob_score_\n",
    "print(f\"最优参数 - 决策树数量: {n_estimators}\")\n",
    "print(f\"最优参数 - 每个节点分裂时随机选择的特征数量: {max_features}\")\n",
    "print(f\"均方误差 (MSE): {mse:.2f}\")\n",
    "print(f\"均方根误差 (RMSE): {rmse:.2f}\")\n",
    "print(f\"平均绝对误差 (MAE): {mae:.2f}\")\n",
    "print(f\"袋外数据得分 (OOB Score): {oob_score:.2f}\")#\n",
    "#③特征重要性\n",
    "feature_importances = rf.feature_importances_\n",
    "feature_names = ['外向性', '宜人性', '责任心', '情绪稳定性', '开放性']\n",
    "#④可视化预测结果和特征重要性\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei'] # 可根据系统情况选择其他中文字体，如 'Microsoft YaHei'\n",
    "plt.figure(figsize=(18, 6))\n",
    "#子图 1：预测值 vs 真实值散点图\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_test, y_pred,label='预测值与真实值关系')\n",
    "plt.xlabel('真实值')\n",
    "plt.ylabel('预测值')\n",
    "plt.title('预测值 vs 真实值')\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--', label='理想预测线')#绘制对角线\n",
    "plt.legend()\n",
    "# 子图 2：特征重要性饼图\n",
    "plt.subplot(1, 2, 2)\n",
    "#凸显最重要特征\n",
    "index_most_important=np.argmax(feature_importances)\n",
    "explode = [0, 0, 0, 0, 0]\n",
    "explode[index_most_important]=0.1 # 突出显示最重要的特征切片\n",
    "wedges, texts, autotexts = plt.pie(feature_importances, explode=explode, labels=feature_names,autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "#设置文本属性\n",
    "plt.setp(autotexts, size=10, weight=\"bold\")\n",
    "plt.title('特征重要性')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f616186-56b1-4919-a757-c055fb691533",
   "metadata": {},
   "source": [
    "### 代码8.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb78ff0-c477-41fa-8aa2-5d266a3df5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "#(1)模拟生成特征数据与标签数据\n",
    "np.random.seed(0)\n",
    "X = np.vstack([np.random.randn(20, 2)*5 -[10, 10], np.random.randn(20, 2)*5 + [10, 10]])+[30,30]#模拟生成特征数据\n",
    "X=np.round(X) #数据取整\n",
    "y = np.hstack([np.zeros(20), np.ones(20)]) #模拟生成标签数据\n",
    "data=pd.DataFrame() #创建一个空的dataFrame\n",
    "data[[\"情绪稳定性\",\"外向性\"]]=X #存储特征数据到datafrme\n",
    "data[\"心理健康\"]=y #存储标签数据到datafrme\n",
    "print(\"人格与心理健康数据：\",data)\n",
    "data.to_excel(\"人格与心理健康数据.xlsx\",index=False) #导出数据到excel中，方便后续重复使用\n",
    "#(2)绘制两个特征数据的散点图，并以心理健康标签数据标注散点颜色\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei'] # 可根据系统情况选择其他中文字体，如 'Microsoft YaHei'\n",
    "# 根据心理健康标签将数据分为两类\n",
    "class_0 = data[data[\"心理健康\"] == 0]\n",
    "class_1 = data[data[\"心理健康\"] == 1]\n",
    "#绘制散点图\n",
    "plt.scatter(class_0[\"情绪稳定性\"], class_0[\"外向性\"], c='blue', label='心理健康类别 0')\n",
    "plt.scatter(class_1[\"情绪稳定性\"], class_1[\"外向性\"], c='red', label='心理健康类别 1')\n",
    "plt.title('情绪稳定性和外向性的散点图')\n",
    "plt.xlabel('情绪稳定性')\n",
    "plt.ylabel('外向性')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4604410f-9af5-4ac5-912a-38b314933d49",
   "metadata": {},
   "source": [
    "### 代码8.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cb2dd1-7703-43ce-b261-9d17035451c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "#（1）导入数据库数据\n",
    "data=pd.read_excel(\"人格与心理健康数据.xlsx\")\n",
    "X=data[[\"情绪稳定性\",\"外向性\"]].values\n",
    "y=data[\"心理健康\"].values\n",
    "#（2）创建并训练 SVM 分类器\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(X, y)\n",
    "#（3）获取超平面参数\n",
    "w = clf.coef_[0]\n",
    "b = clf.intercept_[0]\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "xx = np.linspace(x_min, x_max)\n",
    "yy = -(w[0] * xx + b) / w[1]\n",
    "#计算间隔距离 d\n",
    "d = 2 / np.linalg.norm(w)\n",
    "#计算间隔边界\n",
    "yy_up = -(w[0] * xx + b + 1) / w[1]\n",
    "yy_down = -(w[0] * xx + b - 1) / w[1]\n",
    "#获取支持向量\n",
    "support_vectors = clf.support_vectors_\n",
    "#（4）可视化最优超平面及分隔空间\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei'] # 可根据系统情况选择其他中文字体，如 'Microsoft YaHei'\n",
    "plt.scatter(X[y == 0][:, 0], X[y == 0][:, 1], c='b', label='心理健康类别0')\n",
    "plt.scatter(X[y ==1][:, 0], X[y == 1][:, 1], c='r', label='心理健康类别1')\n",
    "plt.plot(xx, yy, 'g--', label='最优超平面')\n",
    "plt.plot(xx, yy_up, 'k--', label='分隔空间上边界')\n",
    "plt.plot(xx, yy_down, 'k--', label='分隔空间下边界')\n",
    "#标记支持向量\n",
    "plt.scatter(support_vectors[:, 0], support_vectors[:, 1], s=100, edgecolors='y', facecolors='none', label='支持向量')\n",
    "#标注间隔距离 d\n",
    "mid_point_x = (x_min + x_max) / 2\n",
    "mid_point_y = -(w[0] * mid_point_x + b) / w[1]\n",
    "plt.annotate(f'd = {d:.2f}', xy=(mid_point_x, mid_point_y), xytext=(mid_point_x+1.5, mid_point_y-4),\n",
    "arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "plt.xlabel('情绪稳定性')\n",
    "plt.ylabel('外向性')\n",
    "plt.title('基于两个特征变量的支持向量机分类')\n",
    "plt.ylim(5,60)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af32be2-48ce-498c-bc6f-9e72d6b507fc",
   "metadata": {},
   "source": [
    "### 代码8.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505dbd6d-4264-46d0-b0b0-587dc0f3c39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "#（1）生成模拟数据\n",
    "np.random.seed(0)\n",
    "X = np.sort(5 * np.random.rand(40, 1)+30, axis=0) # 模拟生成40个外向性得分数据\n",
    "y = np.sin(X).ravel()+20 # 模拟生成40个心理健康得分数据\n",
    "y[::5] += 3 * (0.5 - np.random.rand(8)) # 给数据增加点噪声和随机变化\n",
    "#（2）确定epsilon参数\n",
    "param_grid = {'epsilon': np.linspace(0.1, 1, 10)}# 定义要搜索的epsilon参数范围\n",
    "#创建SVR模型\n",
    "svr = SVR(kernel='rbf', C=100, gamma=0.1)\n",
    "#使用GridSearchCV进行网格搜索和交叉验证\n",
    "grid_search = GridSearchCV(svr, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X, y)\n",
    "#获取最优的epsilon参数\n",
    "best_epsilon = grid_search.best_params_['epsilon']\n",
    "print(f\"最优的epsilon参数: {best_epsilon:.4f}\")\n",
    "#（3）拟合SVR模型\n",
    "svr_rbf = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=best_epsilon)\n",
    "svr_rbf.fit(X, y)\n",
    "# （4）计算管道空间的上下边界\n",
    "y_rbf = svr_rbf.predict(X)\n",
    "y_upper = y_rbf + best_epsilon\n",
    "y_lower = y_rbf - best_epsilon\n",
    "# （5）计算评价指标\n",
    "mse = mean_squared_error(y, y_rbf)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y, y_rbf)\n",
    "#打印评价指标\n",
    "print(f\"均方误差 (MSE): {mse:.4f}\")\n",
    "print(f\"均方根误差 (RMSE): {rmse:.4f}\")\n",
    "print(f\"决定系数 (R的平方): {r2:.4f}\")\n",
    "# (6)可视化拟合结果\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei'] # 可根据系统情况选择其他中文字体，如 'Microsoft YaHei'\n",
    "plt.scatter(X, y, c='k', label='数据点')\n",
    "plt.plot(X, y_rbf, c='g', label='最优超平面', linewidth=2)\n",
    "plt.fill_between(X.flatten(), y_lower, y_upper, color='gray', alpha=0.2, label='管道空间')\n",
    "#在图中添加评价指标\n",
    "textstr = f\"均方误差 (MSE): {mse:.4f}均方根误差 (RMSE): {rmse:.4f}决定系数 (R的平方): {r2:.4f}\"\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "plt.text(0.05, 0.95, textstr, transform=plt.gca().transAxes, fontsize=10,verticalalignment='top', bbox=props)\n",
    "plt.xlabel('外向性')\n",
    "plt.ylabel('心理健康')\n",
    "plt.title('支持向量机回归任务')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1f8126-616e-4b4b-af5b-ec3aa5339870",
   "metadata": {},
   "source": [
    "### 代码8.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda80d78-6b11-4bb0-858f-8db29f0c9f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#(1)欧式距离计算函数\n",
    "def euclidean_distance_numpy(x, y):\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    return np.linalg.norm(x - y)\n",
    "#(2)准备数据\n",
    "data={\"你\":[170,60],\"大毛\":[180,60],\"二毛\":[170,68],\"小明\":[167,64]}\n",
    "#计算与你各个同学之间的欧式距离：\n",
    "for name in [\"大毛\",\"二毛\",\"小明\"]:\n",
    "    distance = euclidean_distance_numpy(data[\"你\"], data[name])\n",
    "    print(name+\"与你的欧氏距离为:\", distance)\n",
    "#(3)把数据放置到二维空间中目测\n",
    "# 提取每个学生的坐标\n",
    "your_coords = data[\"你\"]\n",
    "big_hair_coords = data[\"大毛\"]\n",
    "second_hair_coords = data[\"二毛\"]\n",
    "xiaoming_coords = data[\"小明\"]\n",
    "#设置图片可以显示中文\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei'] # 可根据系统情况选择其他中文字体，如 'Microsoft YaHei'\n",
    "colors=[\"red\",\"blue\",\"green\",\"purple\"]\n",
    "labels=[\"你\",\"大毛\",\"二毛\",\"小明\"]\n",
    "#创建散点图，用不同颜色表示不同学生\n",
    "for i in range(len(data)):\n",
    "    label=labels[i]\n",
    "    color=colors[i]\n",
    "    coords=data[label]\n",
    "    plt.scatter(coords[0], coords[1], color=color, label=label)\n",
    "    if label!=\"你\":\n",
    "        your_coords = data[\"你\"]\n",
    "        plt.plot([your_coords[0], coords[0]], [your_coords[1], coords[1]],color=color, label=label+'与你的距离')\n",
    "#添加标题和坐标轴标签\n",
    "plt.title('同学数据点及与你的距离')\n",
    "plt.xlabel('身高')\n",
    "plt.ylabel('体重')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4cedee-1646-4c90-b9e4-a6d2b0fb918b",
   "metadata": {},
   "source": [
    "### 代码8.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850cb86b-c118-41eb-b835-cadb0c09bb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def kmeans(X, K, max_iterations=100):  # 随机初始化K个质心\n",
    "    n_samples, n_features = X.shape    # 从数据集中随机选择K个样本作为初始质心\n",
    "    centroids = X[np.random.choice(n_samples, K, replace=False)]\n",
    "    #创建一个存放迭代过程中质心和簇标签的字典\n",
    "    centroids_labels_history={}\n",
    "    for i in range(max_iterations):\n",
    "        # 分配样本到最近的质心\n",
    "        # 用于存储每个样本所属的簇标签\n",
    "        labels = []\n",
    "        for sample in X:\n",
    "            # 计算当前样本到每个质心的距离\n",
    "            distances = [np.linalg.norm(sample - centroid) for centroid in centroids]\n",
    "            # 找到距离最近的质心的索引\n",
    " \n",
    "            label = np.argmin(distances)\n",
    "            labels.append(label)\n",
    "        labels = np.array(labels)\n",
    "        #把数据质心和对应的簇成员标签存放进字典\n",
    "        centroids_labels_history[i]=(centroids,labels)\n",
    "        # 更新质心\n",
    "        new_centroids = []\n",
    "        for k in range(K):\n",
    "            # 找到属于当前簇的所有样本\n",
    "            cluster_samples = X[labels == k]\n",
    "            if len(cluster_samples) > 0:\n",
    "                # 计算当前簇内所有样本的均值作为新的质心\n",
    "                new_centroid = np.mean(cluster_samples, axis=0)\n",
    "                new_centroids.append(new_centroid)\n",
    "            else:                # 如果某个簇为空，则重新随机选择一个质心\n",
    "                new_centroids.append(X[np.random.choice(n_samples)])\n",
    "        new_centroids = np.array(new_centroids)\n",
    "        # 判断质心是否不再变化，如果是则提前结束迭代\n",
    "        if np.allclose(centroids, new_centroids):\n",
    "            break\n",
    "        centroids = new_centroids\n",
    "    return centroids_labels_history\n",
    "#生成班级60人的体重和身高数据\n",
    "np.random.seed(42)\n",
    "X = np.vstack([np.random.normal(loc=[55,160], scale=5, size=(20, 2)),\n",
    "                    np.random.normal(loc=[65,170], scale=5, size=(20, 2)),\n",
    "                    np.random.normal(loc=[60,180], scale=5, size=(20, 2))\n",
    "                    ])\n",
    "#设置聚类的簇数\n",
    "K = 3\n",
    "#调用K - 均值聚类函数\n",
    "centroids_labels_history = kmeans(X, K)\n",
    "iterations=len(centroids_labels_history)#最终迭代次数\n",
    "print(\"最终聚类结果的三个质心分别是：\",centroids_labels_history[iterations-1][0])\n",
    "#绘制迭代过程中的质心和分类簇变化图\n",
    "n_col=3#设置多图的列数\n",
    "n_row, remainder=divmod(iterations,n_col)#计算多图的行数\n",
    "if remainder>0:#如果有余数，行数加1\n",
    "    n_row+=1\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei'] #可根据系统情况选择其他中文字体，如 'Microsoft YaHei'\n",
    "for key,value in centroids_labels_history.items():#遍历聚类迭代历史数据\n",
    "    plt.subplot(n_row,n_col,key+1)#在n_row行和n_col列的网格中绘制第key+1个子图\n",
    "    centroids,labels=value#将第key次质心和簇标签读取出来\n",
    "    plt.scatter(X[:, 1], X[:, 0], c=labels, cmap='viridis')#绘制散点，并根据簇标签分类图形\n",
    "    plt.scatter(centroids[:, 1], centroids[:, 0], marker='X', s=100, c='red') #绘制三个质心\n",
    "    quotient, remainder = divmod(key, n_col) #判断绘图位置    \n",
    "    if quotient==n_row-1:#最后一行显示x轴的label\n",
    "        plt.xlabel('体重')\n",
    "    if remainder==0:#左边第一列显示y轴的标签\n",
    "        plt.ylabel('身高')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1745ad-c0ce-4707-95d4-c8038c8e3b3e",
   "metadata": {},
   "source": [
    "### 代码8.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee5f2c0-88e9-4717-907c-75ee8fa0fe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "# （1）#生成班级60人的体重和身高数据\n",
    "np.random.seed(42)\n",
    "X = np.vstack([np.random.normal(loc=[55, 160], scale=5, size=(20, 2)), \n",
    "             np.random.normal(loc=[65, 170], scale=5, size=(20, 2)),\n",
    "              np.random.normal(loc=[60, 180], scale=5, size=(20, 2))\n",
    "              ])\n",
    "#（2）定义聚类算法\n",
    "algorithms = {\"K -均值聚类（KMeans）\": KMeans(n_clusters=3, random_state=42),                                                                                                                                     \"小批量 K - 均值算法（MiniBatchKMeans）\": MiniBatchKMeans(n_clusters=3, random_state=42),\"凝聚式层次聚类（AgglomerativeClustering）\": AgglomerativeClustering(n_clusters=3),\"密度空间聚类应用算法（DBSCAN）\": DBSCAN(eps=3, min_samples=5),\"高斯混合模型聚类（GaussianMixture）\": GaussianMixture(n_components=3, random_state=42), \"谱聚类（SpectralClustering）\": SpectralClustering(n_clusters=3, random_state=42) }\n",
    "#（3）遍历所有的距离算法，并将聚类结果可视化\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei'] # 可根据系统情况选择其他中文字体，如 'Microsoft YaHei'\n",
    "n_algorithms = len(algorithms)\n",
    "n_rows =2\n",
    "n_cols = 3\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 10))\n",
    "#存储每个算法的评价指标结果\n",
    "evaluation_results = {}\n",
    "#遍历每个算法进行聚类和可视化 \n",
    "for i, (name, algorithm) in enumerate(algorithms.items()):\n",
    "    row = i // n_cols\n",
    "    col = i % n_cols\n",
    "    if name == \"高斯混合模型聚类（GaussianMixture）\":\n",
    "        labels = algorithm.fit_predict(X)\n",
    "    else:\n",
    "        algorithm.fit(X)\n",
    "        labels = algorithm.labels_\n",
    "    #计算评价指标 \n",
    "    try:\n",
    "        silhouette = silhouette_score(X, labels)\n",
    "        calinski_harabasz = calinski_harabasz_score(X, labels)\n",
    "        davies_bouldin = davies_bouldin_score(X, labels)\n",
    "        evaluation_results[name] = {'Silhouette Score': silhouette,'Calinski - Harabasz Score': calinski_harabasz,'Davies - Bouldin Score': davies_bouldin}\n",
    "    except:\n",
    "    #处理可能出现的异常，例如 DBSCAN 可能只有一个簇，导致某些指标无法计算\n",
    "        evaluation_results[name] = {'Silhouette Score': None,'Calinski - Harabasz Score': None,'Davies - Bouldin Score': None}\n",
    "    axes[row, col].scatter(X[:, 1], X[:, 0], c=labels, cmap='viridis')\n",
    "    axes[row, col].set_title(name)\n",
    "    axes[row, col].set_xlabel('身高')\n",
    "    axes[row, col].set_ylabel('体重')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#（4）提取评价指标数据\n",
    "algorithm_names = list(evaluation_results.keys())\n",
    "silhouette_scores = [evaluation_results[name]['Silhouette Score'] for name in algorithm_names]\n",
    "calinski_harabasz_scores = [evaluation_results[name]['Calinski - Harabasz Score'] for name in algorithm_names]\n",
    "davies_bouldin_scores = [evaluation_results[name]['Davies - Bouldin Score'] for name in algorithm_names]\n",
    "#（5）创建新的图形来展示评价指标\n",
    "fig, axs = plt.subplots(3, 1, figsize=(10, 15))\n",
    "#定义三种不同的颜色用于区分三个子图的柱子\n",
    "colors = ['skyblue', 'lightgreen', 'orange']\n",
    "metrics = ['Silhouette Score', 'Calinski - Harabasz Score', 'Davies - Bouldin Score']\n",
    "#绘制轮廓系数横向柱状图\n",
    "y_pos = np.arange(len(algorithm_names))\n",
    "axs[0].barh(y_pos, silhouette_scores, color=colors[0])\n",
    "axs[0].set_yticks(y_pos)\n",
    "axs[0].set_yticklabels(algorithm_names)\n",
    "#绘制 Calinski - Harabasz 指数横向柱状图\n",
    "axs[1].barh(y_pos, calinski_harabasz_scores, color=colors[1])\n",
    "axs[1].set_yticks(y_pos)\n",
    "axs[1].set_yticklabels(algorithm_names)\n",
    "#绘制 Davies - Bouldin 指数横向柱状图\n",
    "axs[2].barh(y_pos, davies_bouldin_scores, color=colors[2])\n",
    "axs[2].set_yticks(y_pos)\n",
    "axs[2].set_yticklabels(algorithm_names)\n",
    "#创建图例\n",
    "handles = [plt.Rectangle((0, 0), 1, 1, color=color) for color in colors]\n",
    "fig.legend(handles, metrics, loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdbface-95ea-404a-96dc-a395cbd6e6f9",
   "metadata": {},
   "source": [
    "### 代码8.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1809d28d-817e-4bda-9132-e63d8b35258b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#模拟身高和体重数据\n",
    "np.random.seed(42)\n",
    "#假设身高和体重存在一定的线性关系，这里模拟100个样本\n",
    "n_samples = 50\n",
    "height_mean = 170\n",
    "height_std = 10\n",
    "\n",
    "weight_mean = 70\n",
    "weight_std = 10\n",
    "# 生成身高数据\n",
    "height = np.random.normal(height_mean, height_std, n_samples)\n",
    "#体重和身高有一定的正相关关系\n",
    "weight = 0.5 * height + np.random.normal(weight_mean - 0.5 * height_mean, weight_std, n_samples)\n",
    "#组合身高和体重数据为二维数组\n",
    "data = np.column_stack((height, weight))\n",
    "#计算变量方差\n",
    "print(\"身高方差:\",np.var(height))\n",
    "print(\"体重方差:\",np.var(weight))\n",
    "print(\"总方差:\",np.var(weight)+np.var(height))\n",
    "#初始化角度和方差列表\n",
    "angles = np.arange(0, 181, 1)\n",
    "variances = []\n",
    "#遍历每个角度\n",
    "for angle in angles:\n",
    "# 将角度转换为弧度\n",
    "    rad_angle = np.radians(angle)\n",
    "# 定义旋转矩阵\n",
    "    rotation_matrix = np.array([[np.cos(rad_angle), -np.sin(rad_angle)],[np.sin(rad_angle), np.cos(rad_angle)]])\n",
    "# 旋转坐标轴    \n",
    "    rotated_data = np.dot(data, rotation_matrix)\n",
    "# 计算投影到第一维的方差 \n",
    "    projected_data = rotated_data[:, 0]\n",
    "    variance = np.var(projected_data)\n",
    "    variances.append(variance)\n",
    "#获取方差最大值和相应的直线角度\n",
    "max_index=np.argmax(np.array(variances))\n",
    "print(\"形成最大方差的角度是：\",angles[max_index])\n",
    "print(\"新的一维数据方差最大值是：\",variances[max_index])\n",
    "min_index=np.argmin(np.array(variances))\n",
    "print(\"形成最小方差的角度是：\",angles[min_index])\n",
    "print(\"新的一维数据方差最小值是：\",variances[min_index])\n",
    "# 绘制方差随角度变化的曲线\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei'] \n",
    "plt.plot(angles, variances)\n",
    "plt.xlabel('直线角度')\n",
    "plt.ylabel('投影数据点的方差')\n",
    "plt.title('投影直线旋转角度与降维后数据方差的关系')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3faffc0-da43-40ea-a947-30682fa28363",
   "metadata": {},
   "source": [
    "### 代码8.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d98fcc-3011-428f-aa17-68907f3c1a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA, FactorAnalysis, KernelPCA\n",
    "from sklearn.manifold import LocallyLinearEmbedding, TSNE\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import entropy\n",
    "#（1）生成15维度的模拟数据\n",
    "np.random.seed(42)\n",
    "n_samples =200\n",
    "n_features = 15\n",
    "\n",
    "X = np.random.randn(n_samples, n_features)\n",
    "#（2）定义降维方法\n",
    "methods = {'PCA': PCA(n_components=3), \n",
    "          'Factor Analysis': FactorAnalysis(n_components=3),\n",
    "          'Kernel PCA': KernelPCA(n_components=3, kernel='rbf'),\n",
    "          'LLE': LocallyLinearEmbedding(n_components=3),\n",
    "          't-SNE': TSNE(n_components=3)} \n",
    "#存储降维结果和评价指标\n",
    "results = {}\n",
    "silhouette_scores = {}\n",
    "entropy_scores = {}\n",
    "#颜色列表，用于区分不同评价指标的条形图\n",
    "colors =['skyblue', 'lightgreen']\n",
    "#(3)进行降维并计算评价指标 \n",
    "for name, method in methods.items():\n",
    "    X_transformed = method.fit_transform(X)#输入数据进行训练\n",
    "    results[name] = X_transformed #训练结果存储到字典\n",
    "    #计算轮廓系数\n",
    "    kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "    labels = kmeans.fit_predict(X_transformed)\n",
    "    silhouette_scores[name] = silhouette_score(X_transformed, labels)\n",
    "    #计算信息熵 \n",
    "    hist, _ = np.histogramdd(X_transformed, bins=10)\n",
    "    prob = hist / hist.sum()\n",
    "    entropy_scores[name] = entropy(prob.flatten())\n",
    "#(4)可视化评价效果\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei'] #设置中文显示问题\n",
    "plt.rcParams['axes.unicode_minus'] = False # 解决负号显示问题\n",
    "fig, axes = plt.subplots(2, 1, figsize=(8, 12))\n",
    "#绘制轮廓系数的横向条形图\n",
    "axes[0].barh(list(silhouette_scores.keys()), list(silhouette_scores.values()), color=colors[0], label='轮廓系数')\n",
    "# 绘制信息熵的横向条形图\n",
    "axes[1].barh(list(entropy_scores.keys()), list(entropy_scores.values()), color=colors[1], label='信息熵')\n",
    "# 设置总图例\n",
    "lines, labels = [], []\n",
    "for ax in fig.axes:\n",
    "    axLine, axLabel = ax.get_legend_handles_labels()\n",
    "    lines.extend(axLine)\n",
    "    labels.extend(axLabel)\n",
    "fig.legend(lines, labels, loc='upper right')\n",
    "plt.show()\n",
    "#(5)获取降维各因子与原始维度的系数\n",
    "np.set_printoptions(precision=2) # 设置打印选项，保留两位小数\n",
    "def compontes_sort(arr):\n",
    "    arr=np.abs(arr.T)\n",
    "    m,n=arr.shape\n",
    "    columns=[\"成分\"+str(i+1) for i in range(n)]\n",
    "    index=[\"特征\"+str(i) for i in range(m)]\n",
    "    df=pd.DataFrame(data=arr,columns=columns,index=index)\n",
    "    max_column_names = df.idxmax(axis=1) #获取每行最大值的列名\n",
    "    df_list=[]\n",
    "    for column in df.columns:\n",
    "        mask=max_column_names==column\n",
    "        indices = max_column_names.index[mask]\n",
    "        new_df=df.loc[indices].copy(deep=True)\n",
    "        new_df=new_df.sort_values(by=column,ascending= False)\n",
    "        df_list.append(new_df)\n",
    "    df=pd.concat(df_list)\n",
    "    return df\n",
    "pca = methods['PCA']\n",
    "pca_components = pca.components_\n",
    "pca_components=compontes_sort(pca_components)\n",
    "print(\"主成分分析系数表：\",pca_components)\n",
    "fa = methods['Factor Analysis']\n",
    "fa_components = fa.components_\n",
    "fa_components=compontes_sort(fa_components)\n",
    "print(\"因子分析系数表：\",fa_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855dc984-1bcf-4f44-80ba-fcca326d164c",
   "metadata": {},
   "source": [
    "### 代码8.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3b8cf3-87da-49e5-a99d-ab6bd1816f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "#（1）创建感知机的类\n",
    "class Perceptron:\n",
    "    def __init__(self, learning_rate=0.1, max_iter=10000):   \n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iter = max_iter\n",
    "        self.weights = None #用于存储权重系数的动态属性\n",
    "        self.bias = None #用于存储阈限值的动态属性\n",
    "        self.history = {} #用于存储历史数值的动态属性\n",
    "    def fit(self, X, y): \n",
    "        n_samples, n_features = X.shape\n",
    "        #初始化权重和偏置为0 \n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0 \n",
    "        for iteration in range(self.max_iter):\n",
    "            misclassified =False\n",
    "            for i in range(n_samples):\n",
    "                #对输入与权重系数乘机加和，然后与阈限self.bias比\n",
    "                linear_output = np.dot(X[i], self.weights) - self.bias\n",
    "                prediction =1 if linear_output >= 0 else 0\n",
    "                #如果预测错误，则更新权重和偏置 \n",
    "                if prediction != y[i]:\n",
    "                    self.weights += self.learning_rate * (y[i] - prediction) * X[i]\n",
    "                    self.bias += -self.learning_rate * (y[i]-prediction)\n",
    "                    misclassified =True \n",
    "            self.history[iteration] = (self.weights.copy(), self.bias)#将历史数据存入字典\n",
    "            #如果没有错误分类的样本，则提前结束\n",
    "            if not misclassified:\n",
    "                break\n",
    "    def predict(self, X):  \n",
    "        linear_output = np.dot(X, self.weights) - self.bias\n",
    "        return np.where(linear_output >= 0, 1, 0)\n",
    "#（2）生成的等待分类的二维数据并创建感知机模型实例并完成训练\n",
    "np.random.seed(0)\n",
    "X = np.vstack([np.random.randn(20, 2) * 5 - [10, 10], np.random.randn(20, 2) * 5 + [10, 10]]) + [30, 30]\n",
    "X = np.round(X)\n",
    "y = np.hstack([np.zeros(20), np.ones(20)]) # 模拟生成标签数据\n",
    "perceptron = Perceptron(learning_rate=0.1, max_iter=10000) #创建实例\n",
    "perceptron.fit(X, y) #训练模型\n",
    "#（3）调用训练好的模型进行预测\n",
    "predictions = perceptron.predict(X)\n",
    "print(\"预测结果:\", predictions)\n",
    "print(\"最终权重:\", perceptron.weights)\n",
    "print(\"最终阈值:\", perceptron.bias)\n",
    "print(\"总迭代次数:\",len(perceptron.history))\n",
    "#（4）可视化感知机学习过程\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei'] # 可根据系统情况选择其他中文字体，如 'Microsoft YaHei' \n",
    "plt.rcParams['axes.unicode_minus'] = False # 解决负号显示问题\n",
    "#绘制被分类数据的散点图\n",
    "plt.scatter(X[y == 0][:, 0], X[y == 0][:, 1], c='b', label='类别0')\n",
    "plt.scatter(X[y ==1][:, 0], X[y == 1][:, 1], c='r', label='类别1')\n",
    "#获取 x 轴范围\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "#选择要绘制直线的迭代次数值\n",
    "iterations=len(perceptron.history) #根据存放的历史数据长度，计算实际迭代次数\n",
    "steps,remainder = divmod(iterations, 5) #选择历史迭代中的其中五次来绘图\n",
    "keys=[key for key in np.arange(0,iterations,steps)] #获取还要绘图的5个超平面的键\n",
    "keys.append((iterations-1))#把最后一次添加到迭代次数值列表中\n",
    "# 依据历史数据绘制所有分割直线\n",
    "for key in keys:\n",
    "    weights, bias=perceptron.history[key] #从历史数据字典中获取选中的权重和阈值数据 \n",
    "    if weights[1] != 0:\n",
    "        x_vals = np.linspace(x_min, x_max,100)\n",
    "        y_vals = -(weights[0] * x_vals - bias) / weights[1]\n",
    "        random_rgb = np.random.rand(3)#生成三个0到1之间的随机数作为RGB分量\n",
    "        color = mcolors.to_rgba(random_rgb) # 将RGB值转换为RGBA格式\n",
    "        plt.plot(x_vals, y_vals, color=color, label=f'Iter {key+1}')\n",
    "plt.xlabel('特征1')\n",
    "plt.ylabel('特征2')\n",
    "plt.title('感知机学习过程展示')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69b8b2b-69d6-4666-9e92-c8ae00c0dfc3",
   "metadata": {},
   "source": [
    "### 代码8.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be145cb-0673-4b2b-85b2-cf6e313cbb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#阶跃函数\n",
    "def step_function(x):\n",
    "    return np.array([1 if i >=0 else 0 for i in x])\n",
    "# Sigmoid函数\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "# ReLU函数\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "# Softmax函数\n",
    "def softmax(x):\n",
    "    if len(x.shape) > 1:\n",
    "        x = x - np.max(x, axis=1, keepdims=True)\n",
    "        exp_x = np.exp(x)\n",
    "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "    else:\n",
    "        x = x - np.max(x)\n",
    "        exp_x = np.exp(x)\n",
    "        return exp_x / np.sum(exp_x)\n",
    "#生成输入值\n",
    "x = np.arange(-20.0, 20.0, 0.1)\n",
    "#计算各激活函数的输出\n",
    "y_step = step_function(x)\n",
    "y_sigmoid = sigmoid(x)\n",
    "y_relu = relu(x)\n",
    "#设置中文显示和坐标轴负号\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams[\n",
    "'axes.unicode_minus'] = False\n",
    "# 绘制阶跃函数图像\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(x, y_step)\n",
    "plt.title('阶跃函数')\n",
    "plt.ylim(-0.1, 1.1)\n",
    "#绘制 Sigmoid 函数图像\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(x, y_sigmoid)\n",
    "plt.title('Sigmoid函数')\n",
    "plt.ylim(-0.1, 1.1)\n",
    "#绘制 ReLU 函数图像\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(x, y_relu)\n",
    "plt.title('ReLU函数')\n",
    "plt.ylim(-0.1, 5.0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#测试 Softmax 函数\n",
    "test_vector = np.array([1, 2, 3, 4, 5])\n",
    "softmax_output = softmax(test_vector)\n",
    "print(\"Softmax 函数输入向量:\", test_vector)\n",
    "print(\"Softmax 函数输出概率分布:\", softmax_output)\n",
    "print(\"Softmax 函数输出概率之和:\", np.sum(softmax_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439f1ba2-192d-4c0b-8b70-70d06d3bc9be",
   "metadata": {},
   "source": [
    "### 代码8.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22f7d04-7513-4d32-943f-ac0639ec986b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#定义sigmoid函数\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "#定义线性可分逻辑门函数\n",
    "def and_gate(x1, x2): #与门\n",
    "    #线性计算： w1*x1 + w2*x2 + b \n",
    "    weight1, weight2, bias = 10, 10, -15 \n",
    "    linear_output = weight1 * x1 + weight2 * x2 + bias\n",
    "    sigmoid_out=round(sigmoid(linear_output))\n",
    "    return sigmoid_out\n",
    "def or_gate(x1, x2): #或门\n",
    "    #线性计算： w1*x1 + w2*x2 + b \n",
    "    weight1, weight2, bias = 10, 10, -5 \n",
    "    linear_output = weight1 * x1 + weight2 * x2 + bias\n",
    "    sigmoid_out=round(sigmoid(linear_output))\n",
    "    return sigmoid_out\n",
    "def nand_gate(x1, x2): #与非门\n",
    "    #线性计算：w1*x1 + w2*x2 + b \n",
    "    weight1, weight2, bias = -10, -10, 15 \n",
    "    linear_output = weight1 * x1 + weight2 * x2 + bias\n",
    "    sigmoid_out=round(sigmoid(linear_output))\n",
    "    return sigmoid_out \n",
    "#生成两个测谎题目的所有可能答案组合\n",
    "input_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "#计算三个逻辑门的输出\n",
    "and_output = [and_gate(x[0], x[1]) for x in input_data]\n",
    "or_output = [or_gate(x[0], x[1]) for x in input_data]\n",
    "nand_output = [nand_gate(x[0], x[1]) for x in input_data]\n",
    "outputs = [and_output, or_output, nand_output]\n",
    "titles = ['与门分类结果', '或门分类结果', '与非门分类结果']\n",
    "#创建子图\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei'] # 可根据系统情况选择其他中文字体，如 'Microsoft YaHei' \n",
    "plt.rcParams['axes.unicode_minus'] = False # 解决负号显示问题 \n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "# 用于存储图例句柄和标签\n",
    "handles = []\n",
    "labels = []\n",
    "for i in range(len(outputs)):\n",
    "    output = outputs[i]\n",
    "    axes[i].scatter(input_data[np.array(output) ==0][:, 0], input_data[np.array(output) == 0][:, 1], c='r',label='输出0')\n",
    "    axes[i].scatter(input_data[np.array(output) ==1][:, 0], input_data[np.array(output) == 1][:, 1], c='b',label='输出1')\n",
    "    axes[i].set_title(titles[i])\n",
    "    axes[i].set_xlabel('答案1')\n",
    "    axes[i].set_ylabel('答案2')\n",
    "    axes[i].set_xlim(-1, 2)\n",
    "    axes[i].set_ylim(-1, 2)\n",
    "   # 只在第一个子图中获取图例句柄和标签\n",
    "    if i == 0:\n",
    "        handles, labels = axes[i].get_legend_handles_labels()\n",
    "# 在整个图形中添加一个图例\n",
    "fig.legend(handles, labels, loc=2, bbox_to_anchor=(0.9, 0.85))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3080aa8b-4772-4738-bfb7-b4ab2cf912d7",
   "metadata": {},
   "source": [
    "### 代码8.17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3bbfc3-fdff-4992-b2a9-8ce027d415ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#定义sigmoid函数\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "#定义线性可分逻辑门函数\n",
    "def and_gate(x1, x2): #与门\n",
    "    #线性计算： w1*x1 + w2*x2 + b \n",
    "    weight1, weight2, bias = 10, 10, -15 \n",
    "    linear_output = weight1 * x1 + weight2 * x2 + bias\n",
    "    sigmoid_out=round(sigmoid(linear_output))\n",
    "    return sigmoid_out\n",
    "def or_gate(x1, x2): #或门\n",
    "    #线性计算： w1*x1 + w2*x2 + b \n",
    "    weight1, weight2, bias = 10, 10, -5 \n",
    "    linear_output = weight1 * x1 + weight2 * x2 + bias\n",
    "    sigmoid_out=round(sigmoid(linear_output))\n",
    "    return sigmoid_out\n",
    "def nand_gate(x1, x2): #与非门\n",
    "    #线性计算：w1*x1 + w2*x2 + b \n",
    "    weight1, weight2, bias = -10, -10, 15 \n",
    "    linear_output = weight1 * x1 + weight2 * x2 + bias\n",
    "    sigmoid_out=round(sigmoid(linear_output))\n",
    "    return sigmoid_out\n",
    "#通过线性可分逻辑门函数组合实现线性不可分逻辑门\n",
    "def xor_gate(x1,x2): #异或门\n",
    "    R1=or_gate(x1,x2) #通过\"或门\"获得R1\n",
    "    R2=nand_gate(x1,x2) #通过\"与非门\"获得R2\n",
    "    y=and_gate(R1,R2) #R1和R2通过\"与门\"获得y\n",
    "    return y\n",
    "#生成两个测谎题目的所有可能答案组合\n",
    "input_data1 = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "#生成横轴和纵轴-1.1到2之间的矩形内100个平均分布的点\n",
    "x = np.linspace(-1.1, 2, 10)\n",
    "y = np.linspace(-1.1, 2, 10)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "input_data2 = np.column_stack([X.flatten(), Y.flatten()])\n",
    "# 通过异或门函数生成数据点的分类\n",
    "output1 = [xor_gate(x[0], x[1]) for x in input_data1]\n",
    "output2 = [xor_gate(x[0], x[1]) for x in input_data2]\n",
    "#将inputdata2和output2数据合并，并输出到excel里，以备后续训练多层感知机使用\n",
    "output2_arr=np.array(output2).reshape(len(output2),1)\n",
    "data=np.column_stack((input_data2,output2_arr)) #合并输入和输出数据\n",
    "np.random.shuffle(data)#随机打乱顺序\n",
    "df=pd.DataFrame(data=data,columns=[\"输入1\",\"输入2\",\"输出\"])\n",
    "df.to_excel(\"异或门函数输入和输出数据.xlsx\",index=False)\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']#设置 matplotlib 支持中文\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "#创建包含两个子图的图形\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "#绘制 input_data1 的散点图\n",
    "axes[0].scatter(input_data1[np.array(output1) == 0][:, 0], input_data1[np.array(output1) == 0][:, 1], c='r', label='输出0')\n",
    "axes[0].scatter(input_data1[np.array(output1) == 1][:, 0], input_data1[np.array(output1) == 1][:, 1], c='b', label='输出1')\n",
    "axes[0].set_title('input_data1 异或门分类结果')\n",
    "axes[0].set_xlabel('答案1')\n",
    "axes[0].set_ylabel('答案2')\n",
    "axes[0].set_xlim(-1.1, 2)\n",
    "axes[0].set_ylim(-1.1, 2)\n",
    "#绘制 input_data2 的散点图\n",
    "axes[1].scatter(input_data2[np.array(output2) == 0][:, 0], input_data2[np.array(output2) == 0][:, 1], c='r', label='输出0')\n",
    "axes[1].scatter(input_data2[np.array(output2) == 1][:, 0], input_data2[np.array(output2) == 1][:, 1], c='b', label='输出1')\n",
    "axes[1].set_title('input_data2 异或门分类结果')\n",
    "axes[1].set_xlabel('答案1')\n",
    "axes[1].set_ylabel('答案2')\n",
    "axes[1].set_xlim(-1.1, 2)\n",
    "axes[1].set_ylim(-1.1, 2)\n",
    "#添加图例\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='upper center',bbox_to_anchor=(0.4, 0.85))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f004e6f-3f11-4949-b4de-9ae6f35bfda8",
   "metadata": {},
   "source": [
    "### 代码8.18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9346644d-acf9-4db0-914e-7cb881ee1096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def cross_entropy(y_true, y_pred):\n",
    "    #防止对数计算出现无穷大\n",
    "    y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "    return -np.sum(y_true * np.log(y_pred))\n",
    "#示例数据\n",
    "# 理想硬币的概率分布\n",
    "p= np.array([0.5,0.5])\n",
    "#实验硬币的概率分布\n",
    "q = np.array([0.6, 0.4])\n",
    "ce = cross_entropy(p, q)\n",
    "print(f\"单个样本的交叉熵: {ce}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f62595-2eee-4d3a-9ab9-174c07861ccd",
   "metadata": {},
   "source": [
    "### 代码8.19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70519ef7-8246-4cba-a2d4-6fe415108b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# （1）定义计算函数\n",
    "#sigmoid激活函数\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "#交叉熵损失函数\n",
    "def cross_entropy_loss(y_true, y_pred):\n",
    "    epsilon =1e-7 # 防止log(0)\n",
    "    return -(y_true * np.log(y_pred + epsilon) + (1 - y_true) * np.log(1 - y_pred + epsilon))\n",
    "#（2）前向传播步骤\n",
    "def forward_propagation(x_2,y_t,ω_21,ω_22,v_1_other_addend,v_2_other_addend):\n",
    "    v_1 = ω_21 * x_2+v_1_other_addend   #步骤⑤：计算 v1\n",
    "    R_2 = sigmoid(v_1)   #步骤④：计算 R_2\n",
    "    v_2 = ω_22 * R_2+v_2_other_addend   #步骤③： 计算 v_2\n",
    "    y = sigmoid(v_2)   #步骤②：计算 y    \n",
    "    L = cross_entropy_loss(y_t, y)  #步骤①：计算交叉熵损失\n",
    "    print(\"模型预测的交叉熵是：\",L)\n",
    "    return L,y,R_2,\n",
    "#（3）反向传播步骤\n",
    "def barkward_propagation(x_2,y_t,ω_22,R_2):\n",
    "    dL_dy = -(y_t / y - (1 - y_t) / (1 - y)) # 步骤①：计算 ∂L/∂y\n",
    "    dy_dv2 = y * (1 - y)  #步骤②：计算 ∂y/∂v_2\n",
    "    dv2_dω22 = R_2  #步骤③：计算 ∂v_2/∂ω_22 和 ∂v_2/∂R_2\n",
    "    dv2_dR2 = ω_22\n",
    "    dR2_dv1 = R_2 * (1 - R_2)  #步骤④：计算 ∂R_2/∂v_1\n",
    "    dv1_dω21 = x_2  #步骤⑤：计算 ∂v_1/∂ω_21\n",
    "    #链式求导\n",
    "    dL_dω22 = dL_dy * dy_dv2 * dv2_dω22\n",
    "    dL_dω21 = dL_dy * dy_dv2 * dv2_dR2 * dR2_dv1 * dv1_dω21\n",
    "    return dL_dω22,dL_dω21\n",
    "#（4）设定输入数据\n",
    "x_2 = 0.5 # 示例值，可根据实际情况修改\n",
    "y_t = 1 # 真实标签值，示例值，可根据实际情况修改\n",
    "ω_21 = 0.3 # 示例值，可根据实际情况修改\n",
    "ω_22 = 0.4 # 示例值，可根据实际情况修改\n",
    "v_1_other_addend=1.8 #代表输入值x_1和x_0的加权和\n",
    "v_2_other_addend=1.2 #代表输入值R_1和R_0的加权和\n",
    "#（5）执行前向传播和反向传播5次，观察交叉熵的变化情况\n",
    "alpha=5 #学习率\n",
    "for i in range(5):\n",
    "    L,y,R_2=forward_propagation(x_2,y_t,ω_21,ω_22,v_1_other_addend,v_2_other_addend)  #前向传播计算\n",
    "    dL_dω22,dL_dω21=barkward_propagation(x_2,y_t,ω_22,R_2) #反向传播计算\n",
    "    ω_22=ω_22-alpha*dL_dω22  #利用梯度下降法更新ω_22\n",
    "    ω_21=ω_21-alpha*dL_dω21  #利用梯度下降法更新ω_21\n",
    "    print(\"第\" + str(i + 1) + \"次模型输出:\")\n",
    "    print(\"预测值y和交叉熵L：\", y)\n",
    "    print(\"预测值y和交叉熵L：\", L)\n",
    "    print(\"更新后的参数ω_21和ω_22：\",np.round(ω_21,2) ,np.round(ω_22,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81763cce-9cba-4881-b2fd-5fd558cd5a3b",
   "metadata": {},
   "source": [
    "### 代码8.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59391bf1-0d7f-4582-a571-bb68929448be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#（1）定义前向计算和反向计算用到的函数\n",
    "# sigmoid激活函数\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "#交叉熵损失函数\n",
    "def cross_entropy_loss(y_true, y_pred):\n",
    "    epsilon =1e-7 # 防止log(0)\n",
    "    m = y_true.shape[0]\n",
    "    loss = -np.sum(y_true * np.log(y_pred + epsilon) + (1 - y_true) * np.log(1 - y_pred + epsilon)) / m\n",
    "    return loss\n",
    "#计算模型预测准确率\n",
    "def calculate_accuracy(y_pred_proba, y_true):\n",
    "    y_pred = np.where(y_pred_proba >=0.5, 1, 0)#模型输出大于等于0.5转化为1，否则为0。\n",
    "    correct_count = np.sum(y_pred == y_true) #模型输出与真实标签相同的个数\n",
    "    total_count = len(y_true) #总的样本数\n",
    "    accuracy = correct_count / total_count if total_count > 0 else 0 #计算预测正确的比例\n",
    "    return accuracy\n",
    "#（2）创建多层感知机模型的类\n",
    "class MultiLayerPerceptron:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.weights1 = np.random.rand(self.input_size + 1, self.hidden_size)\n",
    "        self.weights2 = np.random.rand(self.hidden_size + 1, self.output_size)\n",
    "        self.loss_and_accuracy_history={\"loss\":[],\"accuracy\":[]} #存放迭代过程中的历史数据\n",
    "    def forward_propagation(self, X):#前向传播\n",
    "        X_with_bias = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "        self.hidden_layer = sigmoid(np.dot(X_with_bias, self.weights1))\n",
    "        hidden_layer_with_bias = np.hstack((np.ones((self.hidden_layer.shape[0], 1)), self.hidden_layer))\n",
    "        self.output_layer = sigmoid(np.dot(hidden_layer_with_bias, self.weights2))\n",
    "        return self.output_layer\n",
    "    def back_propagation(self, X, y, output):#反向传播\n",
    "        m = y.shape[0]\n",
    "       #计算交叉熵损失对输出层激活值的导数∂L/∂y\n",
    "        d_loss_d_output = -(y / (output + 1e-7) - (1 - y) / (1 - output + 1e-7))\n",
    "       #计算输出层激活值对输出层加权和的导数（sigmoid导数）∂y/∂v2\n",
    "        d_output_d_v2 = output*(1-output)\n",
    "       #输出层加权和对权重2的导数∂v2/∂w2\n",
    "        d_v2_d_w2 = np.hstack((np.ones((self.hidden_layer.shape[0], 1)), self.hidden_layer)).T\n",
    "        #通过链式求导计算输出层权重2的梯度∂L/∂w2\n",
    "        d_loss_d_w2 = np.dot(d_v2_d_w2, d_output_d_v2 * d_loss_d_output) / m\n",
    "        #计算隐藏层激活值对隐藏层加权和的导数∂R/∂v01\n",
    "        d_hidden_d_v01 = self.hidden_layer*(1-self.hidden_layer)\n",
    "        #隐藏层加权和对权重1的导数∂v01/∂w01\n",
    "        d_v01_d_w01 = np.hstack((np.ones((X.shape[0], 1)), X)).T\n",
    "        #计算输出层加权和对隐藏层激活值的导数∂v2/∂R\n",
    "        d_v2_d_hidden = self.weights2[1:, :].T\n",
    "        #通过链式求导计算隐藏层权重的梯度\n",
    "        d_loss_d_w01 = np.dot(d_v01_d_w01, d_hidden_d_v01 * np.dot(d_output_d_v2 * d_loss_d_output, d_v2_d_hidden)) / m\n",
    "        return d_loss_d_w01, d_loss_d_w2\n",
    "#更新权重\n",
    "    def update_weights(self, d_loss_d_w1, d_loss_d_w2, learning_rate):\n",
    "        self.weights1 -= learning_rate * d_loss_d_w1\n",
    "        self.weights2 -= learning_rate * d_loss_d_w2\n",
    "#训练方法\n",
    "    def fit(self, X, y, epochs, learning_rate):\n",
    "        for epoch in range(epochs):\n",
    "            output = self.forward_propagation(X)\n",
    "            loss = cross_entropy_loss(y_true=y, y_pred=output)\n",
    "            accuracy=calculate_accuracy(y_true=y,y_pred_proba=output)\n",
    "            d_loss_d_w1, d_loss_d_w2 = self.back_propagation(X, y, output)\n",
    "            self.update_weights(d_loss_d_w1, d_loss_d_w2, learning_rate)\n",
    "            self.loss_and_accuracy_history[\"loss\"].append(loss) #存储每轮次loss值\n",
    "            self.loss_and_accuracy_history[\"accuracy\"].append(accuracy) #存储每次迭代的accuracy值\n",
    "        return self.weights1, self.weights2\n",
    "#（3）导入前期在异或门章节生成的数据，作为训练数据\n",
    "data=pd.read_excel(\"异或门函数输入和输出数据.xlsx\")\n",
    "X=data[[\"输入1\",\"输入2\"]].values\n",
    "y=data[\"输出\"].values.reshape((len(data),1))\n",
    "#（4）实例化多层感知机并进行4次不同随机种子训练，可视化损失函数和准确率对比训练效果\n",
    "for i in range(4):\n",
    "    np.random.seed(i)#创建多层感知机实例\n",
    "    mlp = MultiLayerPerceptron(input_size=2, hidden_size=2, output_size=1)\n",
    "   #训练模型\n",
    "    weights1, weights2 = mlp.fit(X, y, epochs=10000, learning_rate=0.1)\n",
    "    print(\"随机种子为\"+str(i)+\"的迭代结果：\")\n",
    "    print(\"①输入层到隐藏层的系数 \",weights1)\n",
    "    print(\"②隐藏层到输入层的系数 \",weights2)\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "    plt.plot(mlp.loss_and_accuracy_history[\"loss\"], color=\"r\", label=\"交叉熵\")\n",
    "    plt.plot(mlp.loss_and_accuracy_history[\"accuracy\"], color=\"b\", label=\"正确率\")\n",
    "    plt.xlabel(\"迭代次数\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125ae185-f057-46f2-a090-eda278a0c194",
   "metadata": {},
   "source": [
    "### 代码8.21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec635a26-c5cc-4cd7-8986-2a4e757b99d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(123)\n",
    "#（1）生成数据三个数据集合\n",
    "#①模拟生成1000个真人作答数据\n",
    "real_data = np.random.randint(0, 3, size=(1000, 20))\n",
    "#使其中四个题的答题方向与另外16个题目相反\n",
    "opposite_indices = np.random.choice(20, 4, replace=False) \n",
    "for i in range(1000):    \n",
    "    real_data[i, opposite_indices] = 4 - real_data[i, opposite_indices]\n",
    "#②生成随机作答数据\n",
    "random_data=np.random.randint(0, 4, size=(500, 20))\n",
    "#③生成直线作答数据\n",
    "value = np.random.randint(0, 4)\n",
    "straight_data=np.ones((500, 20)) * value\n",
    "#④合并数据集并打乱顺序\n",
    "X = np.vstack((real_data, random_data, straight_data))#合并量表得分数据\n",
    "y = np.array([1] * 1000 + [2] *500 + [3] * 500) #生成标签数据\n",
    "indices = np.arange(X.shape[0])  #生成一个与总数据集长度的索引数组\n",
    "np.random.shuffle(indices)#把索引数组随机打乱\n",
    "X = X[indices]#用打乱后的索引数值给X数组排序\n",
    "y = y[indices]#用打乱后的索引数值给y数组排序\n",
    "#（2）训练模型并记录过程指标\n",
    "#y①划分训练数据和测试数据集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#②设置模型参数\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(30,), max_iter=100,  random_state=123)\n",
    "train_loss_history = []\n",
    "train_acc_history = []\n",
    "test_loss_history = []\n",
    "test_acc_history = []\n",
    "for epoch in range(100):\n",
    "    mlp.partial_fit(X_train, y_train, classes=np.unique(y))  #训练模型启动\n",
    "    #记录训练集的交叉熵和准确率\n",
    "    y_pred_train = mlp.predict_proba(X_train)\n",
    "    train_loss = log_loss(y_train, y_pred_train)\n",
    "    train_acc = accuracy_score(y_train, mlp.predict(X_train))\n",
    "    train_loss_history.append(train_loss)\n",
    "    train_acc_history.append(train_acc)\n",
    "    #记录测试集的交叉熵和准确率\n",
    "    y_pred_test = mlp.predict_proba(X_test)\n",
    "    test_loss = log_loss(y_test, y_pred_test)\n",
    "    test_acc = accuracy_score(y_test, mlp.predict(X_test))\n",
    "    test_loss_history.append(test_loss)\n",
    "    test_acc_history.append(test_acc)\n",
    "#（3）可视化模型的训练结果\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']#设置图片中文显示\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.subplot(1, 2, 1)#创建第一张子图\n",
    "plt.plot(train_loss_history,color=\"r\",label=\"训练数据交叉熵\")\n",
    "plt.plot(test_loss_history, color=\"b\",label=\"测试数据交叉熵\")\n",
    "plt.xlabel('训练轮数')\n",
    "plt.ylabel('交叉熵')\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)#创建第二张子图\n",
    "plt.plot(train_acc_history, color=\"r\", label=\"训练数据准确率\")\n",
    "plt.plot(test_acc_history, color=\"b\", label=\"测试数据准确率\")\n",
    "plt.xlabel('训练轮数')\n",
    "plt.ylabel('准确率')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
